{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9166970e-62f6-419f-bd6a-8891ead294e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.6/dist-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python-headless) (1.19.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: path in /usr/local/lib/python3.6/dist-packages (16.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: pydicom in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.6/dist-packages (1.1.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.19.5)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (7.16.1)\n",
      "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.0.4)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.2.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (20.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.24.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->keras-tuner) (4.3.3)\n",
      "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/dist-packages (from ipython->keras-tuner) (0.17.2)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.6/dist-packages (from ipython->keras-tuner) (4.7.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from ipython->keras-tuner) (3.0.5)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->keras-tuner) (49.2.1)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->keras-tuner) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorboard->keras-tuner) (0.34.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->keras-tuner) (3.12.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->keras-tuner) (1.20.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->keras-tuner) (3.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->keras-tuner) (0.4.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->keras-tuner) (1.31.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->keras-tuner) (0.9.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->keras-tuner) (1.7.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.0)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.7.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (3.10.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->keras-tuner) (0.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect->ipython->keras-tuner) (0.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->keras-tuner) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->keras-tuner) (4.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: scikeras in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
      "Requirement already satisfied: importlib-metadata<4,>=3 in /usr/local/lib/python3.6/dist-packages (from scikeras) (3.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from scikeras) (0.24.2)\n",
      "Requirement already satisfied: packaging<22.0,>=0.21 in /usr/local/lib/python3.6/dist-packages (from scikeras) (20.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata<4,>=3->scikeras) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata<4,>=3->scikeras) (4.1.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging<22.0,>=0.21->scikeras) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging<22.0,>=0.21->scikeras) (2.4.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.0->scikeras) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.0->scikeras) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.0->scikeras) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.0->scikeras) (1.4.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "     |████████████████████████████████| 292 kB 34.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.19.5)\n",
      "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.1.5)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.3.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (8.4.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.11.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python-headless\n",
    "!pip install path\n",
    "!pip install pydicom\n",
    "!pip install keras-tuner\n",
    "!pip install scikeras\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b528868d-de81-47c3-b95a-c058687e67dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9e47658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import warnings, random, os, pydicom, cv2, glob, re\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionV3, MobileNetV2, VGG19\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, Input, GlobalAveragePooling2D, MaxPooling2D, Conv2D, AveragePooling2D\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "\n",
    "# tf.config.run_functions_eagerly(True)\n",
    "\n",
    "print('Tensorflow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e874c0b9-19f3-494b-8445-0b01a1cbf6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ~/.kaggle\n",
    "! cp kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea97433-0c90-4e80-9b96-0c03c117f06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading rsna-miccai-brain-tumor-radiogenomic-classification.zip to /dli/task\n",
      " 44%|█████████████████▏                     | 5.40G/12.3G [00:27<00:34, 217MB/s]"
     ]
    }
   ],
   "source": [
    "! kaggle competitions download -c rsna-miccai-brain-tumor-radiogenomic-classification\n",
    "! mkdir train\n",
    "! unzip rsna-miccai-brain-tumor-radiogenomic-classification.zip -d train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62a1bbb-b81c-4ead-b425-ab7cd687f85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8a388fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_types = ['FLAIR','T1w','T1wCE','T2w']\n",
    "SIZE = 256\n",
    "NUM_IMAGES = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b62d0602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom_image(path, img_size=SIZE):\n",
    "    dicom = pydicom.read_file(path)\n",
    "    data = dicom.pixel_array\n",
    "    data = cv2.resize(data, (img_size, img_size))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aca9a054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dicom_image('./train/train/00000/FLAIR/Image-154.dcm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e756511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom_images_3d(scan_id, num_imgs=NUM_IMAGES, img_size=SIZE, mri_type=\"FLAIR\"):\n",
    "    files = sorted(glob.glob(f\"./train/train/{scan_id}/{mri_type}/*.dcm\"), \n",
    "               key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n",
    "    middle = len(files)//2\n",
    "    num_imgs2 = num_imgs//2\n",
    "    p1 = max(0, middle - num_imgs2)\n",
    "    p2 = min(len(files), middle + num_imgs2)\n",
    "    img3d = np.stack([load_dicom_image(f) for f in files[p1:p2]]).T \n",
    "    if img3d.shape[-1] < num_imgs:\n",
    "        n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n",
    "        img3d = np.concatenate((img3d,  n_zero), axis = -1)\n",
    "    if np.min(img3d) < np.max(img3d):\n",
    "        img3d = img3d - np.min(img3d)\n",
    "        img3d = img3d / np.max(img3d)     \n",
    "    return img3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f88ac9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BraTS21ID</th>\n",
       "      <th>MGMT_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  BraTS21ID  MGMT_value\n",
       "0     00000           1\n",
       "1     00002           1\n",
       "2     00003           0\n",
       "3     00005           1\n",
       "4     00006           1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = pd.read_csv('./train/train_labels.csv', dtype={0:'object', 1:'int8'})\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a8c4cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_train_val, df_labels_test = train_test_split(df_labels, test_size=0.2, random_state=123)\n",
    "df_labels_train, df_labels_val = train_test_split(df_labels_train_val, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14fdf7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_train():\n",
    "    for i in range(df_labels_train.shape[0]):\n",
    "        x = load_dicom_images_3d(df_labels_train['BraTS21ID'].iloc[i])\n",
    "        y = df_labels_train['MGMT_value'].iloc[i]\n",
    "        yield x, y\n",
    "def generator_val():\n",
    "    for i in range(df_labels_val.shape[0]):\n",
    "        x = load_dicom_images_3d(df_labels_val['BraTS21ID'].iloc[i])\n",
    "        y = df_labels_val['MGMT_value'].iloc[i]\n",
    "        yield x, y\n",
    "def generator_test():\n",
    "    for i in range(df_labels_test.shape[0]):\n",
    "        x = load_dicom_images_3d(df_labels_test['BraTS21ID'].iloc[i])\n",
    "        y = df_labels_test['MGMT_value'].iloc[i]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb7e2776",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = tf.data.Dataset.from_generator(generator_train, args=[], \n",
    "                                          output_types=(tf.int16, tf.int8), \n",
    "                                          output_shapes = (((SIZE, SIZE, NUM_IMAGES), ())))\n",
    "ds_val = tf.data.Dataset.from_generator(generator_val, args=[], \n",
    "                                          output_types=(tf.int16, tf.int8), \n",
    "                                          output_shapes = (((SIZE, SIZE, NUM_IMAGES), ())))\n",
    "ds_test = tf.data.Dataset.from_generator(generator_test, args=[], \n",
    "                                          output_types=(tf.int16, tf.int8), \n",
    "                                          output_shapes = (((SIZE, SIZE, NUM_IMAGES), ())))\n",
    "ds_train = ds_train.batch(8)\n",
    "ds_val = ds_val.batch(8)\n",
    "ds_test = ds_test.batch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8e9f94c-0afc-4c5b-82e7-5964e8491600",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 127, 127, 32) 288         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 127, 127, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 127, 127, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 125, 125, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 125, 125, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 125, 125, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 125, 125, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 125, 125, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 125, 125, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 62, 62, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 62, 62, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 62, 62, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 62, 62, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 60, 60, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 60, 60, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 60, 60, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 29, 29, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 29, 29, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 29, 29, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 29, 29, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 29, 29, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 29, 29, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 29, 29, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 29, 29, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 29, 29, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 29, 29, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 29, 29, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 29, 29, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 29, 29, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 29, 29, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 29, 29, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 29, 29, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 29, 29, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 29, 29, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 29, 29, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 29, 29, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 29, 29, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 29, 29, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 29, 29, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 29, 29, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 29, 29, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 29, 29, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 29, 29, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 29, 29, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 29, 29, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 29, 29, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 29, 29, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 29, 29, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 29, 29, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 29, 29, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 29, 29, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 29, 29, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 29, 29, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 29, 29, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 29, 29, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 29, 29, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 29, 29, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 29, 29, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 29, 29, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 29, 29, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 29, 29, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 29, 29, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 29, 29, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 29, 29, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 29, 29, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 29, 29, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 29, 29, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 29, 29, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 29, 29, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 29, 29, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 29, 29, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 29, 29, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 29, 29, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 29, 29, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 29, 29, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 29, 29, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 29, 29, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 29, 29, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 29, 29, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 29, 29, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 29, 29, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 29, 29, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 29, 29, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 29, 29, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 29, 29, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 29, 29, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 29, 29, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 29, 29, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 29, 29, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 29, 29, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 14, 14, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 14, 14, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 14, 14, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 14, 14, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 14, 14, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 14, 14, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 14, 14, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 14, 14, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 14, 14, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 14, 14, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 14, 14, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 14, 14, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 14, 14, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 14, 14, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 14, 14, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 14, 14, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 14, 14, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 14, 14, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 14, 14, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 14, 14, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 14, 14, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 14, 14, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 14, 14, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 14, 14, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 14, 14, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 14, 14, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 14, 14, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 14, 14, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 14, 14, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 14, 14, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 14, 14, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 14, 14, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 14, 14, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 14, 14, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 14, 14, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 14, 14, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 14, 14, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 14, 14, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 14, 14, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 14, 14, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 14, 14, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 14, 14, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 14, 14, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 14, 14, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 14, 14, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 14, 14, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 14, 14, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 14, 14, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 14, 14, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 14, 14, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 14, 14, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 14, 14, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 14, 14, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 14, 14, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 14, 14, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 14, 14, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 14, 14, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 14, 14, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 14, 14, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 14, 14, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 14, 14, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 14, 14, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 14, 14, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 14, 14, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 14, 14, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 14, 14, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 14, 14, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 14, 14, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 14, 14, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 14, 14, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 14, 14, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 14, 14, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 14, 14, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 14, 14, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 14, 14, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 14, 14, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 14, 14, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 14, 14, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 14, 14, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 14, 14, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 14, 14, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 14, 14, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 14, 14, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 14, 14, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 14, 14, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 14, 14, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 14, 14, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 14, 14, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 14, 14, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 14, 14, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 14, 14, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 14, 14, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 14, 14, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 14, 14, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 14, 14, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 14, 14, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 14, 14, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 14, 14, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 14, 14, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 14, 14, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 14, 14, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 14, 14, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 14, 14, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 14, 14, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 14, 14, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 14, 14, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 14, 14, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 14, 14, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 14, 14, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 14, 14, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 14, 14, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 14, 14, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 14, 14, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 14, 14, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 14, 14, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 14, 14, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 14, 14, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 14, 14, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 14, 14, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 14, 14, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 14, 14, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 14, 14, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 14, 14, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 14, 14, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 14, 14, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 14, 14, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 14, 14, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 6, 6, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 6, 6, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 6, 6, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 6, 6, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 6, 6, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 6, 6, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 6, 6, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 6, 6, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 6, 6, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 6, 6, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 6, 6, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 6, 6, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 6, 6, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 6, 6, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 6, 6, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 6, 6, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 6, 6, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 6, 6, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 6, 6, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 6, 6, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 6, 6, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 6, 6, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 6, 6, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 6, 6, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 6, 6, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 6, 6, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 6, 6, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 6, 6, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 6, 6, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 6, 6, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 6, 6, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 6, 6, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 6, 6, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 6, 6, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 6, 6, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 6, 6, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 6, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 6, 6, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 6, 6, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 6, 6, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 6, 6, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 6, 6, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 6, 6, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 6, 6, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 6, 6, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 6, 6, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 6, 6, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 6, 6, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 6, 6, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 6, 6, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 6, 6, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 6, 6, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 6, 6, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 6, 6, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 6, 6, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 6, 6, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 6, 6, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 6, 6, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 6, 6, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 6, 6, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 6, 6, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 6, 6, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 6, 6, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 6, 6, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 6, 6, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 6, 6, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 6, 6, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 6, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 6, 6, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 6, 6, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,208\n",
      "Trainable params: 21,767,776\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "base_model = InceptionV3(\n",
    "    input_shape=(256, 256, 1),\n",
    "    include_top=False,\n",
    "    weights=None,\n",
    ")\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d965ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_clasificador_propio(n_lay_convs = 3, fil1 = 16, fil2 = 32, fil3 = 64, ks=3, s=2, \n",
    "                              n_lay_dense = 2, nn1 = 32, nn2 = 16, activacion = 'relu'):\n",
    "    output = 1\n",
    "    #filtros = [fil1, fil2, fil3]\n",
    "    neurons = [nn1, nn2]\n",
    "    clasificador = Sequential(name=\"ClasificadorPropio\")\n",
    "    clasificador.add(Input(shape=(SIZE, SIZE, NUM_IMAGES)))\n",
    "    # for i in range(n_lay_convs):\n",
    "        # clasificador.add(Conv2D(filters=filtros[i], kernel_size=ks, strides=s, padding=\"same\", activation=activacion))\n",
    "    base_model = InceptionV3(\n",
    "    input_shape=(SIZE, SIZE, NUM_IMAGES),\n",
    "    include_top=False,\n",
    "    weights=None)\n",
    "    clasificador.add(base_model) \n",
    "    clasificador.add(GlobalAveragePooling2D()) \n",
    "    for i in range(n_lay_dense):\n",
    "        clasificador.add(Dense(neurons[i], activation=activacion))\n",
    "    clasificador.add(Dense(output, activation='sigmoid', name= 'Capa_Salida'))\n",
    "    clasificador.compile(loss='binary_crossentropy',\n",
    "                          optimizer='adam', \n",
    "                          metrics=[\"accuracy\"],\n",
    "                          run_eagerly=True)\n",
    "    return clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf5a24b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ClasificadorPropio\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 6, 6, 2048)        21820352  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                65568     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "Capa_Salida (Dense)          (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 21,886,465\n",
      "Trainable params: 21,852,033\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clasificador_propio = crear_clasificador_propio()\n",
    "clasificador_propio.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2fdf082",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='min', baseline=None, restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "431f0889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "47/47 [==============================] - 144s 3s/step - loss: 0.7493 - accuracy: 0.5134 - val_loss: 0.6870 - val_accuracy: 0.5745\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 84s 2s/step - loss: 0.6960 - accuracy: 0.5187 - val_loss: 0.6862 - val_accuracy: 0.5745\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 83s 2s/step - loss: 0.6893 - accuracy: 0.5561 - val_loss: 0.6827 - val_accuracy: 0.5745\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 82s 2s/step - loss: 0.6877 - accuracy: 0.5481 - val_loss: 0.6848 - val_accuracy: 0.5745\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 83s 2s/step - loss: 0.6785 - accuracy: 0.5829 - val_loss: 0.6822 - val_accuracy: 0.5745\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 83s 2s/step - loss: 0.6504 - accuracy: 0.6471 - val_loss: 0.7785 - val_accuracy: 0.4255\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 83s 2s/step - loss: 0.6566 - accuracy: 0.5989 - val_loss: 0.7291 - val_accuracy: 0.4255\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 83s 2s/step - loss: 0.6139 - accuracy: 0.6925 - val_loss: 0.7329 - val_accuracy: 0.4255\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'): \n",
    "    clasificador_propio.fit(\n",
    "        ds_train,\n",
    "        validation_data=ds_val,\n",
    "        epochs=10,\n",
    "        callbacks=[early_stopping]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fbf0cf4-c5a9-4690-924e-6eb3fa6b67f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6af0f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clasificador_propio.save('./models/clasificador_propio_base.h5')\n",
    "clasificador_propio = tf.keras.models.load_model('./models/clasificador_propio_base.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "309ddcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def darF1Score(model, dataset, print_report=False):\n",
    "    y_true, y_pred = [], []\n",
    "    for x, y in dataset:\n",
    "        y_true.extend(y.numpy().tolist())\n",
    "        y_pred.extend(model.predict(x, verbose=0).round().astype(int).tolist())\n",
    "    if print_report:\n",
    "        print(classification_report(y_true, y_pred))\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return y_true, y_pred, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3cd099d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.93      0.58        40\n",
      "           1       0.50      0.06      0.10        54\n",
      "\n",
      "    accuracy                           0.43        94\n",
      "   macro avg       0.46      0.49      0.34        94\n",
      "weighted avg       0.47      0.43      0.30        94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred, f1 = darF1Score(clasificador_propio, ds_val, print_report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77d21da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(params_grid):\n",
    "    params = {}\n",
    "    for key, list_values in params_grid.items():\n",
    "        params[key] = random.choice(list_values)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b1411aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_model(create_model, params_grid, ds_train, ds_val, n_iter=25):\n",
    "    params_best_model, best_f1_score = None, 0\n",
    "    for i in range(n_iter):\n",
    "        params = get_params(params_grid)\n",
    "        print('Training inter {} for params:\\n'.format(i+1), params)\n",
    "        model = create_model(**params)\n",
    "        with tf.device('/device:GPU:0'): \n",
    "            model.fit(\n",
    "                ds_train,\n",
    "                validation_data=ds_val,\n",
    "                epochs=25,\n",
    "                callbacks=[early_stopping]\n",
    "            )\n",
    "        f1_score = darF1Score(model, ds_val)[2]\n",
    "        print('F1-score for iter {}: {}'.format(i+1, f1_score))\n",
    "        if f1_score > best_f1_score:\n",
    "            params_best_model = params\n",
    "            best_f1_score = f1_score\n",
    "        print('Best F1-score so far:\\n', best_f1_score)\n",
    "        print('Best params so far:\\n', params_best_model)\n",
    "    return params_best_model, best_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0807ea37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training inter 1 for params:\n",
      " {'n_lay_convs': 3, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 5, 's': 2, 'n_lay_dense': 1, 'nn1': 24, 'nn2': 20, 'activacion': 'relu'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.8145 - accuracy: 0.4947 - val_loss: 0.7786 - val_accuracy: 0.4255\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6939 - accuracy: 0.5080 - val_loss: 0.8041 - val_accuracy: 0.4255\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.7006 - accuracy: 0.5374 - val_loss: 0.7610 - val_accuracy: 0.4255\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.6907 - accuracy: 0.5080 - val_loss: 0.6926 - val_accuracy: 0.5745\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.6642 - accuracy: 0.5348 - val_loss: 0.6935 - val_accuracy: 0.4255\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.6226 - accuracy: 0.6524 - val_loss: 0.6948 - val_accuracy: 0.4255\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 84s 2s/step - loss: 0.6188 - accuracy: 0.6390 - val_loss: 0.6962 - val_accuracy: 0.4255\n",
      "Epoch 00007: early stopping\n",
      "F1-score for iter 1: 0.2540489044140997\n",
      "Best F1-score so far:\n",
      " 0.2540489044140997\n",
      "Best params so far:\n",
      " {'n_lay_convs': 3, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 5, 's': 2, 'n_lay_dense': 1, 'nn1': 24, 'nn2': 20, 'activacion': 'relu'}\n",
      "Training inter 2 for params:\n",
      " {'n_lay_convs': 1, 'fil1': 12, 'fil2': 24, 'fil3': 64, 'ks': 5, 's': 4, 'n_lay_dense': 1, 'nn1': 32, 'nn2': 20, 'activacion': 'sigmoid'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 84s 2s/step - loss: 0.7331 - accuracy: 0.5374 - val_loss: 0.7844 - val_accuracy: 0.4255\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 84s 2s/step - loss: 0.6899 - accuracy: 0.5348 - val_loss: 0.7307 - val_accuracy: 0.4255\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 84s 2s/step - loss: 0.6721 - accuracy: 0.5535 - val_loss: 0.7216 - val_accuracy: 0.4255\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 84s 2s/step - loss: 0.6761 - accuracy: 0.5428 - val_loss: 0.7085 - val_accuracy: 0.4255\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6635 - accuracy: 0.5882 - val_loss: 0.7484 - val_accuracy: 0.4255\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6518 - accuracy: 0.6176 - val_loss: 0.8008 - val_accuracy: 0.4255\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6496 - accuracy: 0.6203 - val_loss: 0.8334 - val_accuracy: 0.4255\n",
      "Epoch 00007: early stopping\n",
      "F1-score for iter 2: 0.2540489044140997\n",
      "Best F1-score so far:\n",
      " 0.2540489044140997\n",
      "Best params so far:\n",
      " {'n_lay_convs': 3, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 5, 's': 2, 'n_lay_dense': 1, 'nn1': 24, 'nn2': 20, 'activacion': 'relu'}\n",
      "Training inter 3 for params:\n",
      " {'n_lay_convs': 3, 'fil1': 20, 'fil2': 24, 'fil3': 48, 'ks': 5, 's': 2, 'n_lay_dense': 1, 'nn1': 40, 'nn2': 12, 'activacion': 'relu'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.7887 - accuracy: 0.4973 - val_loss: 0.6828 - val_accuracy: 0.5745\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.6941 - accuracy: 0.5428 - val_loss: 0.6940 - val_accuracy: 0.5745\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.7009 - accuracy: 0.4733 - val_loss: 0.6850 - val_accuracy: 0.5745\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 84s 2s/step - loss: 0.6886 - accuracy: 0.5455 - val_loss: 0.6822 - val_accuracy: 0.5745\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.6671 - accuracy: 0.6524 - val_loss: 0.7482 - val_accuracy: 0.5745\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6382 - accuracy: 0.7032 - val_loss: 0.8304 - val_accuracy: 0.5745\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.6488 - accuracy: 0.6898 - val_loss: 0.7327 - val_accuracy: 0.5745\n",
      "Epoch 00007: early stopping\n",
      "F1-score for iter 3: 0.4192064404830363\n",
      "Best F1-score so far:\n",
      " 0.4192064404830363\n",
      "Best params so far:\n",
      " {'n_lay_convs': 3, 'fil1': 20, 'fil2': 24, 'fil3': 48, 'ks': 5, 's': 2, 'n_lay_dense': 1, 'nn1': 40, 'nn2': 12, 'activacion': 'relu'}\n",
      "Training inter 4 for params:\n",
      " {'n_lay_convs': 2, 'fil1': 20, 'fil2': 24, 'fil3': 64, 'ks': 5, 's': 2, 'n_lay_dense': 2, 'nn1': 24, 'nn2': 12, 'activacion': 'relu'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.7324 - accuracy: 0.5481 - val_loss: 0.6949 - val_accuracy: 0.4255\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6738 - accuracy: 0.5561 - val_loss: 0.6821 - val_accuracy: 0.5745\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.7170 - accuracy: 0.5374 - val_loss: 0.6829 - val_accuracy: 0.5745\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.6918 - accuracy: 0.5775 - val_loss: 0.6861 - val_accuracy: 0.5745\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.6338 - accuracy: 0.6738 - val_loss: 0.7115 - val_accuracy: 0.5745\n",
      "Epoch 00005: early stopping\n",
      "F1-score for iter 4: 0.4192064404830363\n",
      "Best F1-score so far:\n",
      " 0.4192064404830363\n",
      "Best params so far:\n",
      " {'n_lay_convs': 3, 'fil1': 20, 'fil2': 24, 'fil3': 48, 'ks': 5, 's': 2, 'n_lay_dense': 1, 'nn1': 40, 'nn2': 12, 'activacion': 'relu'}\n",
      "Training inter 5 for params:\n",
      " {'n_lay_convs': 1, 'fil1': 12, 'fil2': 40, 'fil3': 48, 'ks': 3, 's': 2, 'n_lay_dense': 2, 'nn1': 40, 'nn2': 16, 'activacion': 'relu'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.7373 - accuracy: 0.4973 - val_loss: 0.7004 - val_accuracy: 0.4255\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.7045 - accuracy: 0.5374 - val_loss: 0.7109 - val_accuracy: 0.4255\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 88s 2s/step - loss: 0.6920 - accuracy: 0.5561 - val_loss: 0.7588 - val_accuracy: 0.4255\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.6445 - accuracy: 0.6417 - val_loss: 0.7989 - val_accuracy: 0.4255\n",
      "Epoch 00004: early stopping\n",
      "F1-score for iter 5: 0.2540489044140997\n",
      "Best F1-score so far:\n",
      " 0.4192064404830363\n",
      "Best params so far:\n",
      " {'n_lay_convs': 3, 'fil1': 20, 'fil2': 24, 'fil3': 48, 'ks': 5, 's': 2, 'n_lay_dense': 1, 'nn1': 40, 'nn2': 12, 'activacion': 'relu'}\n",
      "Training inter 6 for params:\n",
      " {'n_lay_convs': 1, 'fil1': 12, 'fil2': 24, 'fil3': 64, 'ks': 7, 's': 4, 'n_lay_dense': 1, 'nn1': 32, 'nn2': 20, 'activacion': 'relu'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.7862 - accuracy: 0.4599 - val_loss: 1.0848 - val_accuracy: 0.4255\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.7128 - accuracy: 0.4866 - val_loss: 0.7224 - val_accuracy: 0.4255\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.6948 - accuracy: 0.5561 - val_loss: 0.7250 - val_accuracy: 0.4255\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6927 - accuracy: 0.5481 - val_loss: 0.7034 - val_accuracy: 0.4255\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6958 - accuracy: 0.5401 - val_loss: 0.6941 - val_accuracy: 0.4255\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.6930 - accuracy: 0.5080 - val_loss: 0.6946 - val_accuracy: 0.4255\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6931 - accuracy: 0.5187 - val_loss: 0.6920 - val_accuracy: 0.5745\n",
      "Epoch 8/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6929 - accuracy: 0.5107 - val_loss: 0.6938 - val_accuracy: 0.4255\n",
      "Epoch 9/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.6929 - accuracy: 0.5134 - val_loss: 0.6912 - val_accuracy: 0.5745\n",
      "Epoch 10/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.6924 - accuracy: 0.5214 - val_loss: 0.6980 - val_accuracy: 0.4255\n",
      "Epoch 11/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.6930 - accuracy: 0.4733 - val_loss: 0.6938 - val_accuracy: 0.4255\n",
      "Epoch 12/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.6909 - accuracy: 0.5401 - val_loss: 0.7076 - val_accuracy: 0.4255\n",
      "Epoch 00012: early stopping\n",
      "F1-score for iter 6: 0.2540489044140997\n",
      "Best F1-score so far:\n",
      " 0.4192064404830363\n",
      "Best params so far:\n",
      " {'n_lay_convs': 3, 'fil1': 20, 'fil2': 24, 'fil3': 48, 'ks': 5, 's': 2, 'n_lay_dense': 1, 'nn1': 40, 'nn2': 12, 'activacion': 'relu'}\n",
      "Training inter 7 for params:\n",
      " {'n_lay_convs': 2, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 3, 's': 4, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 12, 'activacion': 'sigmoid'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.7072 - accuracy: 0.4813 - val_loss: 0.6955 - val_accuracy: 0.4255\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.6915 - accuracy: 0.5348 - val_loss: 0.7051 - val_accuracy: 0.4255\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6921 - accuracy: 0.5348 - val_loss: 0.6824 - val_accuracy: 0.5745\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6785 - accuracy: 0.6043 - val_loss: 0.6823 - val_accuracy: 0.5745\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6681 - accuracy: 0.6176 - val_loss: 0.6822 - val_accuracy: 0.5745\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6619 - accuracy: 0.6176 - val_loss: 0.6821 - val_accuracy: 0.5745\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6574 - accuracy: 0.6203 - val_loss: 0.6904 - val_accuracy: 0.5745\n",
      "Epoch 8/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.5873 - accuracy: 0.7353 - val_loss: 0.7284 - val_accuracy: 0.5745\n",
      "Epoch 9/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.5776 - accuracy: 0.7273 - val_loss: 0.7714 - val_accuracy: 0.5426\n",
      "Epoch 00009: early stopping\n",
      "F1-score for iter 7: 0.4354911724762336\n",
      "Best F1-score so far:\n",
      " 0.4354911724762336\n",
      "Best params so far:\n",
      " {'n_lay_convs': 2, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 3, 's': 4, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 12, 'activacion': 'sigmoid'}\n",
      "Training inter 8 for params:\n",
      " {'n_lay_convs': 1, 'fil1': 20, 'fil2': 32, 'fil3': 80, 'ks': 5, 's': 2, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 20, 'activacion': 'sigmoid'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 93s 2s/step - loss: 0.7359 - accuracy: 0.4920 - val_loss: 0.6986 - val_accuracy: 0.4255\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6937 - accuracy: 0.4973 - val_loss: 0.6908 - val_accuracy: 0.5745\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.6935 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5745\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6933 - accuracy: 0.5080 - val_loss: 0.6900 - val_accuracy: 0.5745\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.6904 - accuracy: 0.5508 - val_loss: 0.6853 - val_accuracy: 0.5745\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 88s 2s/step - loss: 0.6951 - accuracy: 0.4866 - val_loss: 0.6878 - val_accuracy: 0.5745\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 88s 2s/step - loss: 0.6932 - accuracy: 0.5241 - val_loss: 0.6930 - val_accuracy: 0.5745\n",
      "Epoch 8/25\n",
      "47/47 [==============================] - 88s 2s/step - loss: 0.6892 - accuracy: 0.5802 - val_loss: 0.6953 - val_accuracy: 0.4255\n",
      "Epoch 00008: early stopping\n",
      "F1-score for iter 8: 0.2540489044140997\n",
      "Best F1-score so far:\n",
      " 0.4354911724762336\n",
      "Best params so far:\n",
      " {'n_lay_convs': 2, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 3, 's': 4, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 12, 'activacion': 'sigmoid'}\n",
      "Training inter 9 for params:\n",
      " {'n_lay_convs': 3, 'fil1': 12, 'fil2': 24, 'fil3': 80, 'ks': 7, 's': 4, 'n_lay_dense': 1, 'nn1': 40, 'nn2': 20, 'activacion': 'relu'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.8753 - accuracy: 0.4545 - val_loss: 0.6828 - val_accuracy: 0.5745\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.7346 - accuracy: 0.5053 - val_loss: 0.7000 - val_accuracy: 0.4255\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.7006 - accuracy: 0.4679 - val_loss: 0.6930 - val_accuracy: 0.5745\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6928 - val_accuracy: 0.5745\n",
      "Epoch 00004: early stopping\n",
      "F1-score for iter 9: 0.4192064404830363\n",
      "Best F1-score so far:\n",
      " 0.4354911724762336\n",
      "Best params so far:\n",
      " {'n_lay_convs': 2, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 3, 's': 4, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 12, 'activacion': 'sigmoid'}\n",
      "Training inter 10 for params:\n",
      " {'n_lay_convs': 2, 'fil1': 12, 'fil2': 24, 'fil3': 48, 'ks': 7, 's': 3, 'n_lay_dense': 2, 'nn1': 40, 'nn2': 20, 'activacion': 'sigmoid'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.7095 - accuracy: 0.4866 - val_loss: 0.6910 - val_accuracy: 0.5745\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 84s 2s/step - loss: 0.6938 - accuracy: 0.4920 - val_loss: 0.6844 - val_accuracy: 0.5745\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6820 - accuracy: 0.5214 - val_loss: 0.7166 - val_accuracy: 0.5745\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6713 - accuracy: 0.6016 - val_loss: 0.7359 - val_accuracy: 0.5745\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.6459 - accuracy: 0.6257 - val_loss: 0.8531 - val_accuracy: 0.5745\n",
      "Epoch 00005: early stopping\n",
      "F1-score for iter 10: 0.4192064404830363\n",
      "Best F1-score so far:\n",
      " 0.4354911724762336\n",
      "Best params so far:\n",
      " {'n_lay_convs': 2, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 3, 's': 4, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 12, 'activacion': 'sigmoid'}\n",
      "Training inter 11 for params:\n",
      " {'n_lay_convs': 2, 'fil1': 12, 'fil2': 24, 'fil3': 64, 'ks': 7, 's': 4, 'n_lay_dense': 1, 'nn1': 40, 'nn2': 16, 'activacion': 'relu'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.8127 - accuracy: 0.4599 - val_loss: 0.6991 - val_accuracy: 0.4255\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6945 - accuracy: 0.5214 - val_loss: 0.6929 - val_accuracy: 0.5745\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 83s 2s/step - loss: 0.6863 - accuracy: 0.5508 - val_loss: 0.6853 - val_accuracy: 0.5745\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 84s 2s/step - loss: 0.6568 - accuracy: 0.6203 - val_loss: 0.7016 - val_accuracy: 0.4255\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 84s 2s/step - loss: 0.6170 - accuracy: 0.6818 - val_loss: 0.6983 - val_accuracy: 0.4255\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.5648 - accuracy: 0.7032 - val_loss: 0.7186 - val_accuracy: 0.4255\n",
      "Epoch 00006: early stopping\n",
      "F1-score for iter 11: 0.2540489044140997\n",
      "Best F1-score so far:\n",
      " 0.4354911724762336\n",
      "Best params so far:\n",
      " {'n_lay_convs': 2, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 3, 's': 4, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 12, 'activacion': 'sigmoid'}\n",
      "Training inter 12 for params:\n",
      " {'n_lay_convs': 1, 'fil1': 16, 'fil2': 24, 'fil3': 48, 'ks': 5, 's': 2, 'n_lay_dense': 1, 'nn1': 32, 'nn2': 12, 'activacion': 'sigmoid'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 83s 2s/step - loss: 0.7394 - accuracy: 0.5000 - val_loss: 0.7222 - val_accuracy: 0.4255\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 83s 2s/step - loss: 0.6873 - accuracy: 0.5401 - val_loss: 0.7711 - val_accuracy: 0.4255\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 83s 2s/step - loss: 0.6779 - accuracy: 0.5481 - val_loss: 0.7236 - val_accuracy: 0.4255\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 84s 2s/step - loss: 0.6685 - accuracy: 0.5829 - val_loss: 0.7752 - val_accuracy: 0.4255\n",
      "Epoch 00004: early stopping\n",
      "F1-score for iter 12: 0.2540489044140997\n",
      "Best F1-score so far:\n",
      " 0.4354911724762336\n",
      "Best params so far:\n",
      " {'n_lay_convs': 2, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 3, 's': 4, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 12, 'activacion': 'sigmoid'}\n",
      "Training inter 13 for params:\n",
      " {'n_lay_convs': 1, 'fil1': 16, 'fil2': 40, 'fil3': 48, 'ks': 5, 's': 2, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 20, 'activacion': 'sigmoid'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.7040 - accuracy: 0.4973 - val_loss: 0.7042 - val_accuracy: 0.4255\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.7087 - val_accuracy: 0.4255\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6946 - accuracy: 0.5027 - val_loss: 0.6878 - val_accuracy: 0.5745\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.6852 - accuracy: 0.5722 - val_loss: 0.7403 - val_accuracy: 0.4255\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6901 - accuracy: 0.5508 - val_loss: 0.6821 - val_accuracy: 0.5745\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.6578 - accuracy: 0.6497 - val_loss: 0.6823 - val_accuracy: 0.5745\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6576 - accuracy: 0.6230 - val_loss: 0.6833 - val_accuracy: 0.5745\n",
      "Epoch 8/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.6300 - accuracy: 0.6791 - val_loss: 0.6874 - val_accuracy: 0.5745\n",
      "Epoch 00008: early stopping\n",
      "F1-score for iter 13: 0.4192064404830363\n",
      "Best F1-score so far:\n",
      " 0.4354911724762336\n",
      "Best params so far:\n",
      " {'n_lay_convs': 2, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 3, 's': 4, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 12, 'activacion': 'sigmoid'}\n",
      "Training inter 14 for params:\n",
      " {'n_lay_convs': 3, 'fil1': 16, 'fil2': 32, 'fil3': 80, 'ks': 3, 's': 4, 'n_lay_dense': 1, 'nn1': 40, 'nn2': 12, 'activacion': 'sigmoid'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.7426 - accuracy: 0.4733 - val_loss: 0.6898 - val_accuracy: 0.5745\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 88s 2s/step - loss: 0.6998 - accuracy: 0.4973 - val_loss: 0.6824 - val_accuracy: 0.5745\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 89s 2s/step - loss: 0.6948 - accuracy: 0.4973 - val_loss: 0.6877 - val_accuracy: 0.5745\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 88s 2s/step - loss: 0.6731 - accuracy: 0.5668 - val_loss: 0.7289 - val_accuracy: 0.5745\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 88s 2s/step - loss: 0.6612 - accuracy: 0.6337 - val_loss: 0.7505 - val_accuracy: 0.5745\n",
      "Epoch 00005: early stopping\n",
      "F1-score for iter 14: 0.4192064404830363\n",
      "Best F1-score so far:\n",
      " 0.4354911724762336\n",
      "Best params so far:\n",
      " {'n_lay_convs': 2, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 3, 's': 4, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 12, 'activacion': 'sigmoid'}\n",
      "Training inter 15 for params:\n",
      " {'n_lay_convs': 2, 'fil1': 16, 'fil2': 40, 'fil3': 64, 'ks': 5, 's': 4, 'n_lay_dense': 2, 'nn1': 24, 'nn2': 16, 'activacion': 'relu'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.7551 - accuracy: 0.4733 - val_loss: 0.6851 - val_accuracy: 0.5745\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.6929 - accuracy: 0.5294 - val_loss: 0.9726 - val_accuracy: 0.5745\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 88s 2s/step - loss: 0.6976 - accuracy: 0.5187 - val_loss: 0.6840 - val_accuracy: 0.5745\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.6695 - accuracy: 0.5348 - val_loss: 0.7746 - val_accuracy: 0.5745\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.6732 - accuracy: 0.5401 - val_loss: 1.1097 - val_accuracy: 0.5745\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.6502 - accuracy: 0.6364 - val_loss: 0.7629 - val_accuracy: 0.5745\n",
      "Epoch 00006: early stopping\n",
      "F1-score for iter 15: 0.4192064404830363\n",
      "Best F1-score so far:\n",
      " 0.4354911724762336\n",
      "Best params so far:\n",
      " {'n_lay_convs': 2, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 3, 's': 4, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 12, 'activacion': 'sigmoid'}\n",
      "Training inter 16 for params:\n",
      " {'n_lay_convs': 3, 'fil1': 16, 'fil2': 32, 'fil3': 80, 'ks': 3, 's': 3, 'n_lay_dense': 1, 'nn1': 24, 'nn2': 16, 'activacion': 'relu'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.8223 - accuracy: 0.4840 - val_loss: 0.7005 - val_accuracy: 0.4255\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.7343 - accuracy: 0.4652 - val_loss: 0.7302 - val_accuracy: 0.4255\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.7288 - accuracy: 0.4947 - val_loss: 0.6830 - val_accuracy: 0.5745\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.7534 - accuracy: 0.4866 - val_loss: 0.6856 - val_accuracy: 0.5745\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.7103 - accuracy: 0.5080 - val_loss: 0.6903 - val_accuracy: 0.5745\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.6829 - accuracy: 0.5481 - val_loss: 0.6851 - val_accuracy: 0.5745\n",
      "Epoch 00006: early stopping\n",
      "F1-score for iter 16: 0.4192064404830363\n",
      "Best F1-score so far:\n",
      " 0.4354911724762336\n",
      "Best params so far:\n",
      " {'n_lay_convs': 2, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 3, 's': 4, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 12, 'activacion': 'sigmoid'}\n",
      "Training inter 17 for params:\n",
      " {'n_lay_convs': 1, 'fil1': 16, 'fil2': 40, 'fil3': 48, 'ks': 3, 's': 2, 'n_lay_dense': 2, 'nn1': 24, 'nn2': 20, 'activacion': 'relu'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.7424 - accuracy: 0.4813 - val_loss: 0.6933 - val_accuracy: 0.4255\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.7029 - accuracy: 0.5053 - val_loss: 0.6874 - val_accuracy: 0.5745\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6854 - accuracy: 0.5775 - val_loss: 0.6824 - val_accuracy: 0.5745\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6685 - accuracy: 0.6150 - val_loss: 0.7147 - val_accuracy: 0.5745\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6729 - accuracy: 0.5989 - val_loss: 0.7256 - val_accuracy: 0.4255\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6421 - accuracy: 0.6631 - val_loss: 1.0659 - val_accuracy: 0.4255\n",
      "Epoch 00006: early stopping\n",
      "F1-score for iter 17: 0.2540489044140997\n",
      "Best F1-score so far:\n",
      " 0.4354911724762336\n",
      "Best params so far:\n",
      " {'n_lay_convs': 2, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 3, 's': 4, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 12, 'activacion': 'sigmoid'}\n",
      "Training inter 18 for params:\n",
      " {'n_lay_convs': 3, 'fil1': 16, 'fil2': 24, 'fil3': 80, 'ks': 5, 's': 4, 'n_lay_dense': 1, 'nn1': 32, 'nn2': 16, 'activacion': 'sigmoid'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 84s 2s/step - loss: 0.7279 - accuracy: 0.4973 - val_loss: 0.6847 - val_accuracy: 0.5745\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 83s 2s/step - loss: 0.7028 - accuracy: 0.5053 - val_loss: 0.7089 - val_accuracy: 0.4255\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.6913 - accuracy: 0.5428 - val_loss: 0.7325 - val_accuracy: 0.4255\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.6559 - accuracy: 0.5936 - val_loss: 0.9835 - val_accuracy: 0.5745\n",
      "Epoch 00004: early stopping\n",
      "F1-score for iter 18: 0.4192064404830363\n",
      "Best F1-score so far:\n",
      " 0.4354911724762336\n",
      "Best params so far:\n",
      " {'n_lay_convs': 2, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 3, 's': 4, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 12, 'activacion': 'sigmoid'}\n",
      "Training inter 19 for params:\n",
      " {'n_lay_convs': 1, 'fil1': 12, 'fil2': 24, 'fil3': 80, 'ks': 3, 's': 3, 'n_lay_dense': 1, 'nn1': 24, 'nn2': 12, 'activacion': 'sigmoid'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.7395 - accuracy: 0.4786 - val_loss: 0.6922 - val_accuracy: 0.5745\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.7110 - accuracy: 0.4652 - val_loss: 0.6987 - val_accuracy: 0.4255\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.6992 - accuracy: 0.4733 - val_loss: 0.6945 - val_accuracy: 0.4255\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6935 - accuracy: 0.5241 - val_loss: 0.6841 - val_accuracy: 0.5745\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.6702 - accuracy: 0.5936 - val_loss: 0.7020 - val_accuracy: 0.4255\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6547 - accuracy: 0.6310 - val_loss: 0.7200 - val_accuracy: 0.4255\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.5942 - accuracy: 0.7032 - val_loss: 0.7373 - val_accuracy: 0.4255\n",
      "Epoch 00007: early stopping\n",
      "F1-score for iter 19: 0.2540489044140997\n",
      "Best F1-score so far:\n",
      " 0.4354911724762336\n",
      "Best params so far:\n",
      " {'n_lay_convs': 2, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 3, 's': 4, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 12, 'activacion': 'sigmoid'}\n",
      "Training inter 20 for params:\n",
      " {'n_lay_convs': 3, 'fil1': 20, 'fil2': 24, 'fil3': 64, 'ks': 5, 's': 3, 'n_lay_dense': 1, 'nn1': 24, 'nn2': 20, 'activacion': 'sigmoid'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.7275 - accuracy: 0.5080 - val_loss: 0.7030 - val_accuracy: 0.4255\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.7039 - accuracy: 0.4759 - val_loss: 0.6962 - val_accuracy: 0.4255\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.6964 - accuracy: 0.5160 - val_loss: 0.6821 - val_accuracy: 0.5745\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.6950 - accuracy: 0.5294 - val_loss: 0.6823 - val_accuracy: 0.5745\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.6689 - accuracy: 0.6203 - val_loss: 0.6846 - val_accuracy: 0.5745\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.6302 - accuracy: 0.6791 - val_loss: 0.7492 - val_accuracy: 0.5745\n",
      "Epoch 00006: early stopping\n",
      "F1-score for iter 20: 0.4192064404830363\n",
      "Best F1-score so far:\n",
      " 0.4354911724762336\n",
      "Best params so far:\n",
      " {'n_lay_convs': 2, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 3, 's': 4, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 12, 'activacion': 'sigmoid'}\n",
      "Training inter 21 for params:\n",
      " {'n_lay_convs': 1, 'fil1': 16, 'fil2': 24, 'fil3': 64, 'ks': 3, 's': 4, 'n_lay_dense': 2, 'nn1': 40, 'nn2': 16, 'activacion': 'sigmoid'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.7081 - accuracy: 0.4840 - val_loss: 0.6850 - val_accuracy: 0.5745\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.6811 - accuracy: 0.5882 - val_loss: 0.7130 - val_accuracy: 0.5745\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 87s 2s/step - loss: 0.6849 - accuracy: 0.5802 - val_loss: 0.6996 - val_accuracy: 0.4255\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6399 - accuracy: 0.6898 - val_loss: 0.8354 - val_accuracy: 0.5745\n",
      "Epoch 00004: early stopping\n",
      "F1-score for iter 21: 0.4192064404830363\n",
      "Best F1-score so far:\n",
      " 0.4354911724762336\n",
      "Best params so far:\n",
      " {'n_lay_convs': 2, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 3, 's': 4, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 12, 'activacion': 'sigmoid'}\n",
      "Training inter 22 for params:\n",
      " {'n_lay_convs': 3, 'fil1': 12, 'fil2': 24, 'fil3': 64, 'ks': 5, 's': 2, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 16, 'activacion': 'sigmoid'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.7051 - accuracy: 0.5080 - val_loss: 0.6838 - val_accuracy: 0.5745\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 85s 2s/step - loss: 0.6900 - accuracy: 0.5000 - val_loss: 0.6887 - val_accuracy: 0.5745\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6932 - accuracy: 0.5134 - val_loss: 0.6918 - val_accuracy: 0.5745\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 86s 2s/step - loss: 0.6903 - accuracy: 0.5909 - val_loss: 0.6846 - val_accuracy: 0.5745\n",
      "Epoch 00004: early stopping\n",
      "F1-score for iter 22: 0.4192064404830363\n",
      "Best F1-score so far:\n",
      " 0.4354911724762336\n",
      "Best params so far:\n",
      " {'n_lay_convs': 2, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 3, 's': 4, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 12, 'activacion': 'sigmoid'}\n",
      "Training inter 23 for params:\n",
      " {'n_lay_convs': 3, 'fil1': 12, 'fil2': 40, 'fil3': 48, 'ks': 7, 's': 2, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 16, 'activacion': 'sigmoid'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 97s 2s/step - loss: 0.6997 - accuracy: 0.5027 - val_loss: 0.7139 - val_accuracy: 0.4255\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 91s 2s/step - loss: 0.6935 - accuracy: 0.5080 - val_loss: 0.6916 - val_accuracy: 0.5745\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 98s 2s/step - loss: 0.6909 - accuracy: 0.5535 - val_loss: 0.6885 - val_accuracy: 0.5745\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 100s 2s/step - loss: 0.6829 - accuracy: 0.5588 - val_loss: 0.6880 - val_accuracy: 0.5745\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 103s 2s/step - loss: 0.6852 - accuracy: 0.5561 - val_loss: 0.7024 - val_accuracy: 0.4255\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 106s 2s/step - loss: 0.6267 - accuracy: 0.6872 - val_loss: 0.6854 - val_accuracy: 0.5745\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 91s 2s/step - loss: 0.6114 - accuracy: 0.6925 - val_loss: 0.6933 - val_accuracy: 0.5745\n",
      "Epoch 8/25\n",
      "47/47 [==============================] - 100s 2s/step - loss: 0.5916 - accuracy: 0.7139 - val_loss: 0.7072 - val_accuracy: 0.5745\n",
      "Epoch 9/25\n",
      "47/47 [==============================] - 84s 2s/step - loss: 0.5685 - accuracy: 0.7246 - val_loss: 0.7182 - val_accuracy: 0.5745\n",
      "Epoch 00009: early stopping\n",
      "F1-score for iter 23: 0.4192064404830363\n",
      "Best F1-score so far:\n",
      " 0.4354911724762336\n",
      "Best params so far:\n",
      " {'n_lay_convs': 2, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 3, 's': 4, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 12, 'activacion': 'sigmoid'}\n",
      "Training inter 24 for params:\n",
      " {'n_lay_convs': 1, 'fil1': 20, 'fil2': 24, 'fil3': 48, 'ks': 7, 's': 3, 'n_lay_dense': 2, 'nn1': 40, 'nn2': 20, 'activacion': 'relu'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 92s 2s/step - loss: 0.7520 - accuracy: 0.4492 - val_loss: 0.6925 - val_accuracy: 0.5745\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 121s 3s/step - loss: 0.6999 - accuracy: 0.4893 - val_loss: 0.6994 - val_accuracy: 0.4255\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 100s 2s/step - loss: 0.6947 - accuracy: 0.5241 - val_loss: 0.6827 - val_accuracy: 0.5745\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 90s 2s/step - loss: 0.6835 - accuracy: 0.5882 - val_loss: 0.6968 - val_accuracy: 0.4255\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 131s 3s/step - loss: 0.6491 - accuracy: 0.6471 - val_loss: 0.7945 - val_accuracy: 0.5745\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 90s 2s/step - loss: 0.6693 - accuracy: 0.6711 - val_loss: 0.8182 - val_accuracy: 0.5745\n",
      "Epoch 00006: early stopping\n",
      "F1-score for iter 24: 0.4192064404830363\n",
      "Best F1-score so far:\n",
      " 0.4354911724762336\n",
      "Best params so far:\n",
      " {'n_lay_convs': 2, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 3, 's': 4, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 12, 'activacion': 'sigmoid'}\n",
      "Training inter 25 for params:\n",
      " {'n_lay_convs': 1, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 7, 's': 3, 'n_lay_dense': 2, 'nn1': 24, 'nn2': 20, 'activacion': 'relu'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 110s 2s/step - loss: 0.7750 - accuracy: 0.4572 - val_loss: 0.7032 - val_accuracy: 0.4255\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 137s 3s/step - loss: 0.6955 - accuracy: 0.5107 - val_loss: 0.6946 - val_accuracy: 0.4255\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 140s 3s/step - loss: 0.6760 - accuracy: 0.5775 - val_loss: 1.0575 - val_accuracy: 0.4255\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 143s 3s/step - loss: 0.6737 - accuracy: 0.5829 - val_loss: 1.1160 - val_accuracy: 0.4255\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 138s 3s/step - loss: 0.6892 - accuracy: 0.5775 - val_loss: 0.6882 - val_accuracy: 0.5745\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 138s 3s/step - loss: 0.6621 - accuracy: 0.6096 - val_loss: 0.7078 - val_accuracy: 0.4255\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 143s 3s/step - loss: 0.6492 - accuracy: 0.6658 - val_loss: 0.7358 - val_accuracy: 0.4255\n",
      "Epoch 8/25\n",
      "47/47 [==============================] - 143s 3s/step - loss: 0.6320 - accuracy: 0.6551 - val_loss: 0.6854 - val_accuracy: 0.5745\n",
      "Epoch 9/25\n",
      "47/47 [==============================] - 142s 3s/step - loss: 0.5766 - accuracy: 0.7005 - val_loss: 0.6987 - val_accuracy: 0.4255\n",
      "Epoch 10/25\n",
      "47/47 [==============================] - 143s 3s/step - loss: 0.5221 - accuracy: 0.7620 - val_loss: 0.8310 - val_accuracy: 0.4255\n",
      "Epoch 11/25\n",
      "47/47 [==============================] - 142s 3s/step - loss: 0.5391 - accuracy: 0.7326 - val_loss: 0.6888 - val_accuracy: 0.5745\n",
      "Epoch 00011: early stopping\n",
      "F1-score for iter 25: 0.4192064404830363\n",
      "Best F1-score so far:\n",
      " 0.4354911724762336\n",
      "Best params so far:\n",
      " {'n_lay_convs': 2, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 3, 's': 4, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 12, 'activacion': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "params_grid = {  \n",
    "    'n_lay_convs': [1, 2, 3],\n",
    "    'fil1': [20, 16, 12],\n",
    "    'fil2': [40, 32, 24],\n",
    "    'fil3': [80, 64, 48],\n",
    "    'ks': [3, 5, 7],\n",
    "    's': [2, 3, 4],\n",
    "    'n_lay_dense': [1, 2],\n",
    "    'nn1': [40, 32, 24],\n",
    "    'nn2': [20, 16, 12],\n",
    "    'activacion': ['relu','sigmoid']\n",
    "}\n",
    "\n",
    "params_best_model_propio, best_f1_score_propio = search_model(crear_clasificador_propio, params_grid, ds_train, ds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a57500f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor modelo encontrado por la búsqueda de hiperparámetros obtuvo un F1-score de 0.4354911724762336 con parámetros \n",
      "{'n_lay_convs': 2, 'fil1': 20, 'fil2': 32, 'fil3': 48, 'ks': 3, 's': 4, 'n_lay_dense': 2, 'nn1': 32, 'nn2': 12, 'activacion': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "print('El mejor modelo encontrado por la búsqueda de hiperparámetros obtuvo un F1-score de {} con parámetros \\n{}'.format(best_f1_score_propio, params_best_model_propio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb5f57fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ClasificadorPropio\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 6, 6, 2048)        21820352  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_26  (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 40)                81960     \n",
      "_________________________________________________________________\n",
      "Capa_Salida (Dense)          (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 21,902,353\n",
      "Trainable params: 21,867,921\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "params_best_model_propio = {'n_lay_convs': 3, 'fil1': 12, 'fil2': 24, 'fil3': 80, 'ks': 5, 's': 2, 'n_lay_dense': 1, 'nn1': 40, 'nn2': 16, 'activacion': 'relu'}\n",
    "best_clasificador_propio = crear_clasificador_propio(**params_best_model_propio)\n",
    "best_clasificador_propio.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "785b65f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "59/59 [==============================] - 111s 2s/step - loss: 0.6926 - accuracy: 0.5214\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 112s 2s/step - loss: 0.6926 - accuracy: 0.5214\n",
      "Epoch 3/10\n",
      "59/59 [==============================] - 91s 2s/step - loss: 0.6925 - accuracy: 0.5214\n",
      "Epoch 4/10\n",
      "59/59 [==============================] - 121s 2s/step - loss: 0.6925 - accuracy: 0.5214\n",
      "Epoch 5/10\n",
      "59/59 [==============================] - 143s 2s/step - loss: 0.6924 - accuracy: 0.5214\n",
      "Epoch 6/10\n",
      "59/59 [==============================] - 144s 2s/step - loss: 0.6924 - accuracy: 0.5214\n",
      "Epoch 7/10\n",
      "59/59 [==============================] - 145s 2s/step - loss: 0.6924 - accuracy: 0.5214\n",
      "Epoch 8/10\n",
      "59/59 [==============================] - 143s 2s/step - loss: 0.6924 - accuracy: 0.5214\n",
      "Epoch 9/10\n",
      "59/59 [==============================] - 145s 2s/step - loss: 0.6923 - accuracy: 0.5214\n",
      "Epoch 10/10\n",
      "59/59 [==============================] - 144s 2s/step - loss: 0.6923 - accuracy: 0.5214\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=3, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
    "with tf.device('/device:GPU:0'): \n",
    "    best_clasificador_propio.fit(\n",
    "        ds_train.concatenate(ds_val),\n",
    "        epochs=10,\n",
    "        callbacks=[early_stopping]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8efb7163",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clasificador_propio.save('./models/best_clasificador_propio.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e955f0bb-2a19-4cc6-8e7e-eb88f8d7efa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clasificador_propio = tf.keras.models.load_model('./models/best_clasificador_propio.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d1b7ebf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Reporte para el mejor modelo propio sobre datos de entrenamiento\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       184\n",
      "           1       0.51      1.00      0.67       190\n",
      "\n",
      "    accuracy                           0.51       374\n",
      "   macro avg       0.25      0.50      0.34       374\n",
      "weighted avg       0.26      0.51      0.34       374\n",
      "\n",
      "--------------------------------------------------------\n",
      "Reporte para el mejor modelo propio sobre datos de validación\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        40\n",
      "           1       0.57      1.00      0.73        54\n",
      "\n",
      "    accuracy                           0.57        94\n",
      "   macro avg       0.29      0.50      0.36        94\n",
      "weighted avg       0.33      0.57      0.42        94\n",
      "\n",
      "--------------------------------------------------------\n",
      "Reporte para el mejor modelo propio sobre datos de prueba\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        54\n",
      "           1       0.54      1.00      0.70        63\n",
      "\n",
      "    accuracy                           0.54       117\n",
      "   macro avg       0.27      0.50      0.35       117\n",
      "weighted avg       0.29      0.54      0.38       117\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(54.260000000000005, 0.5, 'Etiquetas predichas')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('--------------------------------------------------------')\n",
    "print('Reporte para el mejor modelo propio sobre datos de entrenamiento')\n",
    "y_true, y_pred, f1 = darF1Score(best_clasificador_propio, ds_train, print_report=True)\n",
    "print('--------------------------------------------------------')\n",
    "print('Reporte para el mejor modelo propio sobre datos de validación')\n",
    "y_true, y_pred, f1 = darF1Score(best_clasificador_propio, ds_val, print_report=True)\n",
    "print('--------------------------------------------------------')\n",
    "print('Reporte para el mejor modelo propio sobre datos de prueba')\n",
    "y_true, y_pred, f1 = darF1Score(best_clasificador_propio, ds_test, print_report=True)\n",
    "plt.figure(figsize=(8,8))\n",
    "mat = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(mat.T, square=True, annot=True, cmap='Blues', fmt='d', cbar=False)\n",
    "plt.xlabel('Etiquetas reales')\n",
    "plt.ylabel('Etiquetas predichas')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
